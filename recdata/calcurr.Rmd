---
title: "A report generated from a pure R script"
output:
  html_document
---
```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  comment = '', fig.width = 6, fig.height = 6, warning = FALSE
)
```
Load the data, plot the data!

```{r }
library(gridExtra)
library(tidymodels)
library(lubridate)
library(readxl)
library(ggcorrplot)
library(knitr)
library(rpart.plot)
library(randomForestExplainer)
library(doParallel)
library(vip)
require(ggplot2)
require(dplyr)
require(ggcorrplot)
require(broom)


data.dir <- "./data/"
petrale <- read.csv(file.path(data.dir,"Petrale_analyzed.data.csv"))
sable <- read.csv(file.path(data.dir,"Sablefish_Analyzed_Data_north.csv"))
sable_DFA <- read.csv(file.path(data.dir,"Sablefish_DFA_Data.csv"))

names(petrale)

#Plot recruits vs year and spawning stock biomass
plot(age.0~year,data=petrale, type="l", main="Recruits per year")
plot(age.0~sp.bio,data=petrale, main="Recruits vs SSB")
```

Spawning biomass and recruitment are not very correlated..not surprising.

```{r }
#Plot correlation
round(cor(petrale %>% 
            dplyr::select(names(petrale)[18:37]) %>% data.frame), 1) %>% 
ggcorrplot(tl.cex=6)

modpetrale <- petrale %>%
  select(-c(X,total.bio,depletion,spr,expl.rate,sp.bio.sd,age.0.sd,yrminusone,resids,log.resids,SR_pred,Label,dev,devsd, LSTbjuv.a,CSTbjuv.a,CSTbjuv.b, Tpre.b, DDegg2)) %>%
  pivot_longer(
    cols=-c(year,sp.bio,age.0),
    values_to="covs_val")

#save(modpetrale, "petrale_model_data.Rds")
```

The time series for LST & CST are highly correlated, also Tpre.a and Tpre.b and DDegg and DDegg2. I remove correlated predictors below; dials::finalize? tune_grid <- parameters(min_n(),mtry())  %>%
  dials::finalize(mtry(), x = baked_data[[1]]$baked_squid 
```{r}
#Do regression with different environmental time series
modpetrale %>% 
  group_by(name) %>%
  do(glance(lm(age.0~sp.bio+covs_val,data=.))) %>%
  bind_rows(modpetrale %>% 
              dplyr::select(-c(covs_val,name)) %>%
              distinct() %>% 
              do(glance(lm(age.0~sp.bio,data=.))) %>%
              mutate(name="sp.bio only")) %>%
  arrange(-adj.r.squared) %>% 
  mutate(across(where(is.double), round, 3)) %>% 
  dplyr::select(-c(r.squared,logLik)) %>% 
  data.frame %>%
  kable()
```


The best covariates are MLDegg (Mean mixed layer depth) and spawner preconditioning degree-days, none other <.05

```{r}
wide_petrale <- modpetrale %>%
  pivot_wider(names_from = name, values_from=covs_val) 

set.seed(100)
pet_split <- initial_split(wide_petrale) #By default, 3/4 data going into training; 1/4 test
pet_train <- training(pet_split)
pet_test <- testing(pet_split)

#Package not working for now, fix later
source("R/fit_split.R")
lm_spec <- linear_reg() %>% 
  set_engine("lm")

pet_split # View the pet_split object.
#  Use the workflows and tidymodels function from above to fit a model to the training data
lm_fit <- fit_split(age.0~DDpre+MLDegg, # specify formula
                    model=lm_spec, # specify model
                    split=pet_split) # specify data








lm_fit %>% 
  collect_metrics()

lm_fit %>%
  collect_predictions()

lm_fit %>% 
  collect_predictions %>% # from tune package, predicting using test data
  mutate(resid=(age.0-.pred)^2) %>% #calculate squared residuals
  summarise(rmse=sqrt(mean(resid)))

fit_split(age.0~sp.bio+MLDegg, # specify formula
          model=lm_spec, # specify model
          metrics=metric_set(rmse,mae,mape), #specify model evaluation criteria.
          split=pet_split) %>% 
  collect_metrics()


#Create new split
set.seed(100)
pet_split <- initial_split(wide_petrale)
pet_train <- training(pet_split)
pet_test <- testing(pet_split)

#Look at range of data to see if we need to center/scale
apply(wide_petrale,2,range)

#  Create a recipe.
pet_recipe <- recipe(age.0~.,data=pet_train) %>% 
  step_center(MLDegg) %>% 
  step_scale(MLDegg) 

#  Prep the recipe. 
pet_prep <- pet_recipe %>% 
  prep(training=pet_train,retain=TRUE)

pet_prep


dt_model <- decision_tree(min_n=5,tree_depth=10) %>% 
  set_engine("rpart") %>%  # Specify the R library
  set_mode("regression") %>%  # Specify regression or classification
  fit(age.0~.,data=juice(pet_prep))

rpart.plot::rpart.plot(dt_model$fit,
                       type=4,
                       extra=101,
                       branch.lty=3,
                       nn=TRUE,
                       roundint=FALSE) 

set.seed(100)
pet_split <- initial_split(wide_petrale,prop=0.90)
pet_train <- training(pet_split)

pet_recipe <- recipe(age.0~.,data=pet_train)

pet_prep <- pet_recipe %>% 
  prep(training=pet_train,retain=TRUE)

rf_model <- rand_forest(trees=2000,mtry=4,mode="regression") %>% #rand_forest is a function in parsnip.
  set_engine("ranger",importance="permutation") %>% # rand_forest is part of the ranger package. We have several options for importance measures.
  fit(age.0~.,data=juice(pet_prep))

```

```{r}
initial_split(wide_petrale, prop=0.96)
```

```{r}
set.seed(100)
pet_split <- initial_split(wide_petrale,prop=0.95)
pet_train <- training(pet_split)
#  First specify the model framework
tune_spec <- rand_forest(mtry = tune(),
              trees = tune(),
              min_n = tune()) %>% 
  set_engine("ranger") %>% 
  set_mode("regression") 

# Now specify the model
tune_wf <- workflow() %>% 
  add_recipe(pet_recipe) %>% 
  add_model(tune_spec)
```


```{r}
dim(vfold_cv(wide_petrale,100))
#set.seed(234) If you were actually doing random subsets, you'd want to set the seed.
pet_folds <- vfold_cv(pet_train,100)

#  Setup parallel processing.
cl <- makeCluster(3)
doParallel::registerDoParallel(cl)
clusterEvalQ(cl, .libPaths("C:/~/R/win-library/4.0/"))


#  Now run the model, which is going to try 20 different values for each of the tuning hyperparameters and do this for 10 resamples of the data.
set.seed(345)
tune_res <- tune_grid(
  tune_wf,
  resamples = pet_folds,
  grid = 20
)

tune_res
```


```{r}
tune_res %>%
  collect_metrics() %>% 
  filter(.metric=="rmse") %>% 
  arrange(mean)
```


```{r}
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  select(mean, min_n, mtry, trees) %>%
  pivot_longer(c(min_n,mtry,trees),
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "rmse")
```


```{r}
md_frame <- min_depth_distribution(rf_model$fit)

plot_min_depth_distribution(md_frame, mean_sample = "top_trees")
```

```{r}
best_rmse <- select_best(tune_res,"rmse")

best_rmse

final_rf <- finalize_model(
  tune_spec,
  best_rmse
)

final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(age.0 ~ .,
    data = juice(pet_prep)) %>%
  vip::vip()


rand_forest(trees=1911,mtry=7,min_n=18,mode="regression") %>% #rand_forest is a function in parsnip.
  set_engine("ranger",importance="permutation") %>% # rand_forest is part of the ranger package. We have several options for importance measures.
  fit(age.0~.,data=juice(pet_prep)) %>% 
  vip()

final_rf %>%
  set_engine("ranger", importance = "impurity") %>%
  fit(age.0 ~ .,
    data = juice(pet_prep)) %>%
  vip::vip(geom = "point")

```

# Rolling stuff

```{r}
#create a rolling resample
pet_rolling <- rolling_origin(wide_petrale, initial =10)

rf_rolling <- rand_forest(trees=2000,mtry=4,mode="regression") %>%
  set_engine("ranger", importance="permutation") %>%
  fit(age.0~.,data=analysis(pet_rolling$splits[[20]]))



#library(randomForestExplainer)
impt_frame<-measure_importance(rf_rolling$fit)

#impt_frame %>% head()
#  I like this plot as a way to illustate how several of the different RF hyperparameters fall out for different features.
plot_multi_way_importance(impt_frame,no_of_labels = 6)
```

Interesting, this makes sp.bio way more important

```{r}
modpetrale %>% 
  group_by(name) %>%
  do(glance(lm(age.0~covs_val,data=.))) %>%
  bind_rows(modpetrale %>% 
              dplyr::select(-c(covs_val,name)) %>%
              distinct() %>% 
              do(glance(lm(age.0~sp.bio,data=.))) %>%
              mutate(name="sp.bio only")) %>%
  arrange(-adj.r.squared) %>% 
  mutate(across(where(is.double), round, 3)) %>% 
  dplyr::select(-c(r.squared,logLik)) %>% 
  data.frame %>%
  kable()

```


```{r}
plot_importance_ggpairs(impt_frame)
```


```{r}
fit_split(age.0 ~ ., 
          model = rand_forest() %>% 
            set_engine("ranger") %>% 
            set_mode("regression"), 
          split = pet_rolling$splits[[1]]) %>% 
  collect_metrics()
```




```{r}
fit_splits <- function(mtry = 3, trees=5, split){
  analysis_set_rf <- analysis(split)
     
    model <- 
      rand_forest(mtry = mtry, trees = trees,mode="regression") %>%
        set_engine("ranger") %>%
        fit(age.0 ~ ., data = analysis_set_rf)

    
    assessment_set_rf <- assessment(split)

    assessment_set_rf %>%
      select(age.0, year) %>%
      mutate(.pred = unlist(predict(model, new_data = assessment_set_rf))) %>% 
      select(age.0, year, .pred)
    
}



last_rmse <- delta_avg_rmse <- 100000
mtry <- 3
ntrees <- 500
# Set-up a grid for mtry and min_n.
mygrid <- expand.grid(mtry=2:35,min_n=2:45)

this_rmse <- rep(0,100)
for(i in 1:100){
#Fit the splits
randomForest_results <- 
  map_df(.x = pet_rolling$splits,
         ~fit_splits(mtry = mtry, trees = ntrees, split = .x))

p <-  ggplot(data=randomForest_results) +
geom_line(aes(y=.pred,x=year)) +
 geom_point(aes(y=age.0,x=year))
p

this_rmse[i] <- randomForest_results %>%
  group_by(year) %>% 
  rmse(age.0, .pred) %>% 
  summarise(avg_rmse = mean(.estimate))
  

delta_avg_rmse <- last_rmse-unlist(this_rmse[i])
last_rmse <- unlist(this_rmse[i])
#mtry <- mtry + 1
ntrees <- ntrees + 1
}

plot(unlist(this_rmse), type="l")
```

```{r}

#  Specify the model for the mtry and min_n grid search. Hold trees constant.
tune_spec <- rand_forest(mtry = tune(),
                         trees = 500,
                         min_n = tune()) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")

#  Setup parallel processing
# all_cores <- parallel::detectCores(logical = FALSE)
# cl <- makePSOCKcluster(all_cores)
# registerDoParallel(cl)
# 
# clusterEvalQ(cl, .libPaths("C:/~/R/win-library/4.0/"))
# 
# mygrid <- expand.grid(mtry=2:35,min_n=2:45)
# #  Run the grid search (this is the function that takes time)
# tune_res <- tune_grid(
#   tune_spec,
#   pet_recipe,
#   resamples = pet_rolling,
#   grid = mygrid
# )
# 
# #  Save it so you never have to do that again.
# tune_res %>% 
#   saveRDS("Hyperparameter_grid.RDS")

tune_res <- readRDS("Hyperparameter_grid.RDS")

#  Plot the contour of hyperparameters with their RMSE
png("hyperparameter_gridsearch_contour.png",width=6,height=6,units="in",res=300)

temp <- tune_res %>%
  collect_metrics() %>% 
  filter(.metric=="rmse") %>% 
  arrange(mean)


p0 <- 
  ggplot(temp) +
  geom_tile(aes(x=mtry,y=min_n,fill=mean)) +
  geom_contour(aes(x=mtry,y=min_n,z=mean),color="black") +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_gradientn("RMSE",colours = terrain.colors(10))
p0

#  Plot without contour lines, hyperparameters with their RMSE
png("hyperparameter_gridsearch_nocontour.png",width=6,height=6,units="in",res=300)
p<-
  ggplot(temp) +
  geom_tile(aes(x=mtry,y=min_n,fill=mean)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_gradientn("RMSE",colours = terrain.colors(10))

#  Extract the best hyperparamters based on RMSE
select_best(tune_res,"rmse")

best_vals <- select_best(tune_res, "rmse")

tune_res %>%
  collect_metrics() %>% 
  filter(.metric=="rmse") %>% 
  arrange(mean)

#  Now use the best mtry and min_n values to see what effect the number of trees has.
treevec <- seq(100,10000,by=100)

#  Model spec with our best mtry and min_n, searching over the vector of trees
tune_spec <- rand_forest(mtry = 2,
                         trees = tune(),
                         min_n = 10) %>%
  set_engine("ranger") %>%
  set_mode("regression")

#  Probably don't need to call this again but doesn't seem to hurt.
all_cores <- parallel::detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)

clusterEvalQ(cl, .libPaths("C:/~/R/win-library/4.0/"))

#  Run grid search over all tree numbers
tune_res <- tune_grid(
  tune_spec,
  pet_recipe,
  resamples = pet_rolling,
  grid = treevec
)

# Save it!
#tune_res %>% 
#  saveRDS("tree_gridsearch.RDS")

tune_res <- readRDS("tree_gridsearch.RDS")


#  How's it look?
tune_res %>%
  collect_metrics() %>% 
  filter(.metric=="rmse") %>% 
  arrange(mean) %>% 
  ggplot(aes(trees,mean)) + 
  geom_point()



```

